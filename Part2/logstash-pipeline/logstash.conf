# Input Section
input {
  # Handle all_logs.csv
  file {
    path => "/usr/share/logstash/logs/all_logs.csv"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    type => "all_logs" # Tag this input as all_logs
  }

  # Handle anomalies.csv
  file {
    path => "/usr/share/logstash/logs/anomalies.csv"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    type => "anomalies" # Tag this input as anomalies
  }

  # Handle blocked_ips.csv
  file {
    path => "/usr/share/logstash/logs/blocked_ips.csv"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    type => "blocked_ips" # Tag this input as blocked_ips
  }
}

# Filter Section
filter {
  csv {
    separator => ","
    columns => ["ClientIP", "RequestCountByIP", "AverageBytesByIP", "Hour", "Anomaly", "ConfidenceScore", "Reason"]
  }

  mutate {
    convert => { "RequestCountByIP" => "integer" }
    convert => { "AverageBytesByIP" => "float" }
    convert => { "ConfidenceScore" => "integer" }
  }
}

# Output Section
output {
  # Send data to Elasticsearch
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "%{type}-index" # Create separate indices for each type (all_logs, anomalies, blocked_ips)
    user => "elastic"
    password => "changeme"
  }

  # Debug output to stdout
  stdout {
    codec => rubydebug
  }
}
